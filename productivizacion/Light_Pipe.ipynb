{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from aux_func import print_metrics, matriz_confusion, curva_roc, curva_pr,ganancia, curva_lift, print_metrics_optimized,matriz_confusion_optimizada\n",
    "#Librarias de modelos\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Transformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Enconders\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuración de visualización de notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos la data\n",
    "data = pd.read_csv('NCDB_1999_to_2014.csv', delim_whitespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiamos los nombres de las columnas para pasarlas a minúscula\n",
    "data.columns= data.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['c_year', 'c_mnth', 'c_wday', 'c_hour', 'c_sev', 'c_vehs', 'c_conf',\n",
       "       'c_rcfg', 'c_wthr', 'c_rsur', 'c_raln', 'c_traf', 'v_id', 'v_type',\n",
       "       'v_year', 'p_id', 'p_sex', 'p_age', 'p_psn', 'p_isev', 'p_safe',\n",
       "       'p_user'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98616"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primero definimos una nueva columna: accidente mortal, que tomará 1s o 0s y contamos cuantos 1 hay (muertos). \n",
    "data['acc_mortal'] = data['c_sev'] == 1\n",
    "data[\"acc_mortal\"] = data[\"acc_mortal\"].astype(int)\n",
    "data.acc_mortal.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a crear un diccionario para poder cambiarlos\n",
    "\n",
    "# Lista con los numeros str con formato '01','02'.'03'...\n",
    "categories_00_format=['%.2d' % i for i in range(100)]\n",
    "categories_00_format\n",
    "\n",
    "#Esta segunda lista son números normales de 1 al 99 en formato int\n",
    "mumbers_0_format=[i for i in range(100)]\n",
    "mumbers_0_format\n",
    "\n",
    "#Unimos las dos listas anteriores\n",
    "categories_00_format.extend(mumbers_0_format)\n",
    "\n",
    "#Esta tercera lista son numeros como string con formato normal que son con los que quiero terminar \n",
    "categories0_format=list([str(i) for i in range(100)])\n",
    "categories0_format.extend(list([str(i) for i in range(100)]))\n",
    "\n",
    "\n",
    "#Las unimos en un diccionario\n",
    "zip_iterator = zip(categories_00_format, categories0_format)\n",
    "diccionary = dict(zip_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitamos la variable v_id, p_id, c_sev y p_isev ya que es info que no tendremos cuando suceda el accidente o que no aportan valor. \n",
    "data=data.drop(['v_id','p_id','c_sev','p_isev'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### df_nulls['v_year'] = df_nulls['v_year'].astype(int)\n",
    "#Reemplazamos los distintos meses para que sean todos iguales ya que algunos tienne un formato como 01,02 o algunos son int\n",
    "data['c_mnth']=data['c_mnth'].replace({'01':'1','02':'2',1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9',10:'10',11:'11',12:'12'})\n",
    "#Reeemplazamos c_wday para que todos sean categoricos, ya que algunos son ints \n",
    "data['c_wday']=data['c_wday'].replace({'01':'1','02':'2',1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9',10:'10',11:'11',12:'12'})\n",
    "#Reemplazamos c_vehs\n",
    "data['c_vehs']=data['c_vehs'].replace(diccionary)\n",
    "#Reemplazamos c_conf\n",
    "data['c_conf']=data['c_conf'].replace(diccionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('acc_mortal',axis=1)\n",
    "y=data.acc_mortal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defnimos columnas para crear dos data frames en base al tipo de encoder que vamos a usar para cada columna\n",
    "\n",
    "ohe_columns=['c_mnth','c_wday','c_hour']\n",
    "catboost_columns=['c_vehs','p_age','v_year','c_year','c_conf','c_rcfg','c_wthr','c_rsur','c_raln','c_traf','v_type','p_sex','p_psn','p_safe','p_user']\n",
    "to_be_ingnored= ['v_year','c_year','acc_mortal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.20,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030147    1\n",
       "2438320    1\n",
       "2718122    1\n",
       "1680156    1\n",
       "2871756    1\n",
       "258223     1\n",
       "4356449    1\n",
       "4394070    1\n",
       "4054737    1\n",
       "3959691    1\n",
       "2095178    1\n",
       "5663031    1\n",
       "5556451    1\n",
       "4561529    1\n",
       "1493881    1\n",
       "3368800    1\n",
       "2797344    1\n",
       "884860     1\n",
       "4432933    1\n",
       "4188707    1\n",
       "2759070    1\n",
       "1347476    1\n",
       "5357877    1\n",
       "1300768    1\n",
       "410495     1\n",
       "51799      1\n",
       "5101500    1\n",
       "627344     1\n",
       "3543120    1\n",
       "4797981    1\n",
       "4853394    1\n",
       "4532430    1\n",
       "2244056    1\n",
       "3523777    1\n",
       "4173882    1\n",
       "4472897    1\n",
       "4995909    1\n",
       "5440293    1\n",
       "1925856    1\n",
       "2793085    1\n",
       "2340327    1\n",
       "1226294    1\n",
       "1161281    1\n",
       "4616914    1\n",
       "3367197    1\n",
       "2385153    1\n",
       "2214418    1\n",
       "218315     1\n",
       "289953     1\n",
       "638092     1\n",
       "Name: acc_mortal, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test==1].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"c_year\":2002,\"c_mnth\":\"12\",\"c_wday\":\"1\",\"c_hour\":\"10\",\"c_vehs\":\"2\",\"c_conf\":\"23\",\"c_rcfg\":\"02\",\"c_wthr\":\"4\",\"c_rsur\":\"3\",\"c_raln\":\"1\",\"c_traf\":\"18\",\"v_type\":\"01\",\"v_year\":\"1998\",\"p_sex\":\"F\",\"p_age\":\"15\",\"p_psn\":\"11\",\"p_safe\":\"02\",\"p_user\":\"1\"}\n"
     ]
    }
   ],
   "source": [
    "print(X_test.iloc[289953].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"c_year\":2008,\"c_mnth\":\"10\",\"c_wday\":\"2\",\"c_hour\":\"20\",\"c_vehs\":\"2\",\"c_conf\":\"22\",\"c_rcfg\":\"01\",\"c_wthr\":\"1\",\"c_rsur\":\"2\",\"c_raln\":\"3\",\"c_traf\":\"18\",\"v_type\":\"01\",\"v_year\":\"2004\",\"p_sex\":\"M\",\"p_age\":\"40\",\"p_psn\":\"11\",\"p_safe\":\"02\",\"p_user\":\"1\"}\n"
     ]
    }
   ],
   "source": [
    "print(X_test.iloc[51799].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_transformer = Pipeline(steps=[\n",
    "                                ('ohe',OneHotEncoder())])\n",
    "cat_transformer=Pipeline(steps=[\n",
    "                                ('cat',ce.cat_boost.CatBoostEncoder())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ohe', ohe_transformer, ohe_columns),\n",
    "        ('cat', cat_transformer, catboost_columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier =  LGBMClassifier()\n",
    "pipe = Pipeline(steps= [('preprocessor', preprocessor),\n",
    "                         ('classifier',classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgm_with_pipe = pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_predictions = model_lgm_with_pipe.predict_proba(X_test)\n",
    "yhat = prob_predictions[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, yhat)\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "ix = np.argmax(gmeans)\n",
    "y_pred_best = (prob_predictions[:,1] >= thresholds[ix]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018339461919462164"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Desktop/aprendizaje_automático/practica_asignatura/productivizacion/modelo.sav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r0/mbpll83s6bvbs55162w48hzw0000gn/T/ipykernel_33406/3504523898.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Guardamos el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../Desktop/aprendizaje_automático/practica_asignatura/productivizacion/modelo.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lgm_with_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/practica_ml/lib/python3.9/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Desktop/aprendizaje_automático/practica_asignatura/productivizacion/modelo.sav'"
     ]
    }
   ],
   "source": [
    "# Guardamos el modelo\n",
    "#filename = '../Desktop/aprendizaje_automático/practica_asignatura/productivizacion/modelo.sav'\n",
    "#joblib.dump(model_lgm_with_pipe, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos las columnas\n",
    "#model_columns = list(X_train.columns)\n",
    "#joblib.dump(model_columns, 'model_columns.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__####################################################################################__"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "practica_ml",
   "language": "python",
   "name": "practica_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
